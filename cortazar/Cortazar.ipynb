{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1409.2329.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1512.05287.pdf\n",
    "\n",
    "http://www.cs.toronto.edu/~graves/preprint.pdf\n",
    "\n",
    "https://machinelearningmastery.com/understanding-stateful-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leo cuentos completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our original text has 735543 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('cortazar.txt').read()\n",
    "print('our original text has ' + str(len(text)) + ' characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimo primeros 1000 caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "era un vampiro. No le tenían miedo pero le dejaban paso\n",
      "cuando él salía de su tumba a la hora precisa de medianoche\n",
      "y entraba al antiguo castillo en procura de su alimento\n",
      "favorito.\n",
      "El rostro de Duggu Van no era agradable. La mucha\n",
      "sangre bebida desde su muerte aparente —en el 1060, a\n",
      "manos de un niño, nuevo David armado de una hondapuñal—\n",
      "había infiltrado en su opaca piel la coloración\n",
      "blanda de las maderas que han estado mucho tiempo debajo\n",
      "del agua. Lo único vivo, en esa cara, eran los ojos.\n",
      "Ojos fijos en la figura de Lady Vanda, dormida como un\n",
      "bebé en el lecho que no conocía más que su liviano cuerpo.\n",
      "Duggu Van caminaba sin hacer ruido. La mezcla de\n",
      "vida y muerte que informaba su corazón se resolvía en\n",
      "cualidades inhumanas. Vestido de azul oscuro, acompa-\n",
      "ñado siempre por un silencioso séquito de perfumes rancios,\n",
      "el vampiro paseaba por las galerías del castillo bus-\n",
      "20\n",
      "cando vivos\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quito numeracíon de páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20\\n', '21\\n', '22\\n', '23\\n', '25\\n', '26\\n', '27\\n', '28\\n', '29\\n', '30\\n', '31\\n', '32\\n', '33\\n', '34\\n', '69\\n', '70\\n', '71\\n', '72\\n', '73\\n', '74\\n', '76\\n', '77\\n', '78\\n', '79\\n', '80\\n', '81\\n', '82\\n', '83\\n', '84\\n', '85\\n', '87\\n', '88\\n', '89\\n', '90\\n', '91\\n', '92\\n', '93\\n', '94\\n', '95\\n', '96\\n', '97\\n', '99\\n', '100\\n', '101\\n', '102\\n', '103\\n', '104\\n', '105\\n', '106\\n', '107\\n', '109\\n', '110\\n', '111\\n', '112\\n', '113\\n', '114\\n', '115\\n', '116\\n', '117\\n', '118\\n', '119\\n', '120\\n', '121\\n', '122\\n', '124\\n', '125\\n', '126\\n', '127\\n', '128\\n', '129\\n', '130\\n', '131\\n', '132\\n', '133\\n', '134\\n', '135\\n', '136\\n', '137\\n', '138\\n', '139\\n', '140\\n', '142\\n', '143\\n', '144\\n', '145\\n', '146\\n', '147\\n', '148\\n', '149\\n', '150\\n', '151\\n', '152\\n', '153\\n', '154\\n', '155\\n', '156\\n', '157\\n', '158\\n', '160\\n', '161\\n', '162\\n', '163\\n', '164\\n', '165\\n', '166\\n', '167\\n', '168\\n', '169\\n', '170\\n', '177\\n', '178\\n', '180\\n', '181\\n', '182\\n', '183\\n', '184\\n', '186\\n', '187\\n', '188\\n', '190\\n', '191\\n', '192\\n', '193\\n', '194\\n', '195\\n', '196\\n', '197\\n', '198\\n', '199\\n', '200\\n', '201\\n', '202\\n', '203\\n', '204\\n', '206\\n', '207\\n', '208\\n', '209\\n', '210\\n', '211\\n', '212\\n', '213\\n', '214\\n', '216\\n', '217\\n', '218\\n', '219\\n', '220\\n', '221\\n', '222\\n', '223\\n', '225\\n', '226\\n', '227\\n', '228\\n', '229\\n', '230\\n', '231\\n', '245\\n', '246\\n', '247\\n', '248\\n', '249\\n', '250\\n', '251\\n', '252\\n', '253\\n', '254\\n', '255\\n', '256\\n', '257\\n', '258\\n', '259\\n', '261\\n', '262\\n', '263\\n', '264\\n', '265\\n', '266\\n', '267\\n', '268\\n', '269\\n', '271\\n', '272\\n', '273\\n', '274\\n', '275\\n', '276\\n', '277\\n', '278\\n', '280\\n', '281\\n', '282\\n', '283\\n', '284\\n', '286\\n', '287\\n', '289\\n', '290\\n', '291\\n', '292\\n', '293\\n', '294\\n', '295\\n', '296\\n', '297\\n', '298\\n', '300\\n', '301\\n', '302\\n', '303\\n', '304\\n', '305\\n', '307\\n', '308\\n', '309\\n', '310\\n', '311\\n', '312\\n', '313\\n', '314\\n', '315\\n', '317\\n', '318\\n', '319\\n', '320\\n', '321\\n', '322\\n', '323\\n', '324\\n', '325\\n', '326\\n', '327\\n', '328\\n', '329\\n', '342\\n', '343\\n', '344\\n', '345\\n', '346\\n', '347\\n', '348\\n', '349\\n', '350\\n', '351\\n', '352\\n', '353\\n', '354\\n', '355\\n', '356\\n', '357\\n', '358\\n', '359\\n', '360\\n', '361\\n', '362\\n', '363\\n', '373\\n', '374\\n', '375\\n', '376\\n', '377\\n', '378\\n', '379\\n', '380\\n', '381\\n', '382\\n', '383\\n', '384\\n', '385\\n', '386\\n', '387\\n', '388\\n', '389\\n', '391\\n', '392\\n', '393\\n', '394\\n', '395\\n', '396\\n', '398\\n', '399\\n', '400\\n', '401\\n', '402\\n', '403\\n', '404\\n', '405\\n', '406\\n', '407\\n', '408\\n', '409\\n', '410\\n', '411\\n', '412\\n', '413\\n', '414\\n', '415\\n', '416\\n', '417\\n', '418\\n', '419\\n', '420\\n', '421\\n', '422\\n', '423\\n', '424\\n', '425\\n', '426\\n', '427\\n', '428\\n', '429\\n', '430\\n', '431\\n', '432\\n', '433\\n', '434\\n', '435\\n', '436\\n', '437\\n', '438\\n', '439\\n', '440\\n', '441\\n', '442\\n', '443\\n', '444\\n', '445\\n', '446\\n', '447\\n', '448\\n', '449\\n', '450\\n', '451\\n', '452\\n', '453\\n', '454\\n', '455\\n', '456\\n', '457\\n', '458\\n', '459\\n', '460\\n', '461\\n', '462\\n', '463\\n', '483\\n', '484\\n', '485\\n', '486\\n', '487\\n', '488\\n', '489\\n', '490\\n', '491\\n', '492\\n', '493\\n', '494\\n', '497\\n', '498\\n', '499\\n', '500\\n', '501\\n', '502\\n', '503\\n', '504\\n', '505\\n', '506\\n', '507\\n', '508\\n', '509\\n', '510\\n', '511\\n', '512\\n', '513\\n', '514\\n', '517\\n', '518\\n', '519\\n', '520\\n', '521\\n', '522\\n', '523\\n', '524\\n', '527\\n', '528\\n', '529\\n', '530\\n', '531\\n', '532\\n', '533\\n', '534\\n', '535\\n', '536\\n', '537\\n', '538\\n', '539\\n', '540\\n', '541\\n', '542\\n', '543\\n', '544\\n', '545\\n', '546\\n', '547\\n', '548\\n']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "numbers=[]\n",
    "while i<len(text):\n",
    "    number = ''\n",
    "    while text[i] in ['0','1','2','3','4','5','6','7','8','9']:\n",
    "        number=number+text[i]\n",
    "        i += 1\n",
    "    if len(number)>0:\n",
    "        if text[i-len(number)-1]=='\\n' and text[i]=='\\n':\n",
    "            numbers.append(number+'\\n')\n",
    "    i += 1\n",
    "print(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quito caracteres no frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_cleaned = text\n",
    "for num in numbers:\n",
    "    text_cleaned = text_cleaned.replace(num,'')\n",
    "text_cleaned = text_cleaned.replace('–','-').replace('[','(').replace(']',')'). \\\n",
    "                replace(\"'\",'\"').replace(\"—\",'-').replace(\"”\", '\"').replace('“','\"').replace('‘','\"').\\\n",
    "                replace(\"«\",'\"').replace(\"»\",'\"').replace('‚',',').replace('*','').replace('ô','o').replace('´',' ').\\\n",
    "                replace('°',' ').replace('º',' ').replace('/',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimo primeros 1000 caracteres limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "era un vampiro. No le tenían miedo pero le dejaban paso\n",
      "cuando él salía de su tumba a la hora precisa de medianoche\n",
      "y entraba al antiguo castillo en procura de su alimento\n",
      "favorito.\n",
      "El rostro de Duggu Van no era agradable. La mucha\n",
      "sangre bebida desde su muerte aparente -en el 1060, a\n",
      "manos de un niño, nuevo David armado de una hondapuñal-\n",
      "había infiltrado en su opaca piel la coloración\n",
      "blanda de las maderas que han estado mucho tiempo debajo\n",
      "del agua. Lo único vivo, en esa cara, eran los ojos.\n",
      "Ojos fijos en la figura de Lady Vanda, dormida como un\n",
      "bebé en el lecho que no conocía más que su liviano cuerpo.\n",
      "Duggu Van caminaba sin hacer ruido. La mezcla de\n",
      "vida y muerte que informaba su corazón se resolvía en\n",
      "cualidades inhumanas. Vestido de azul oscuro, acompa-\n",
      "ñado siempre por un silencioso séquito de perfumes rancios,\n",
      "el vampiro paseaba por las galerías del castillo bus-\n",
      "cando vivos de\n"
     ]
    }
   ],
   "source": [
    "print(text_cleaned[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino train y validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXOLOTL\n",
      "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
      "Iba a verlos al acuario del Jardín des Plantes y me quedaba\n",
      "horas mirándolos, observando su inmovilidad, sus\n",
      "oscuros movimientos. Ahora soy un axolotl.\n",
      "El azar me llevó hasta ellos una mañana de primavera\n",
      "en que París abría su cola de pavo real después de la\n",
      "lenta invernada. Bajé por el bulevar de Port Royal, tomé\n",
      "St. Marcel y L’Hopita\n"
     ]
    }
   ],
   "source": [
    "validation_index = text_cleaned.find('AXOLOTL')\n",
    "print(text_cleaned[validation_index:validation_index+400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383053\n",
      "351034\n"
     ]
    }
   ],
   "source": [
    "text_train = text_cleaned[:validation_index]\n",
    "text_validation = text_cleaned[validation_index:]\n",
    "print(len(text_train))\n",
    "print(len(text_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino cantidad de clases (caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has 734087 total number of characters\n",
      "this corpus has 88 unique characters\n"
     ]
    }
   ],
   "source": [
    "# count the number of unique characters in the text\n",
    "chars_train = set(text_train)\n",
    "chars_test = set(text_validation)\n",
    "chars_set = chars_train.intersection(chars_test)\n",
    "chars = sorted(list(chars_set))\n",
    "\n",
    "# print some of the text, as well as statistics\n",
    "print (\"this corpus has \" +  str(len(text_cleaned)) + \" total number of characters\")\n",
    "print (\"this corpus has \" +  str(len(chars)) + \" unique characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 118621),\n",
       " ('a', 75540),\n",
       " ('e', 73036),\n",
       " ('o', 52626),\n",
       " ('s', 40959),\n",
       " ('n', 38909),\n",
       " ('r', 37276),\n",
       " ('l', 32903),\n",
       " ('i', 28156),\n",
       " ('d', 26654),\n",
       " ('u', 23652),\n",
       " ('t', 22723),\n",
       " ('c', 21882),\n",
       " ('m', 17126),\n",
       " ('p', 14254),\n",
       " ('\\n', 13734),\n",
       " ('b', 9820),\n",
       " (',', 9195),\n",
       " ('y', 6775),\n",
       " ('q', 6764),\n",
       " ('h', 6279),\n",
       " ('.', 6240),\n",
       " ('v', 5883),\n",
       " ('g', 5654),\n",
       " ('í', 4888),\n",
       " ('f', 3266),\n",
       " ('j', 2955),\n",
       " ('ó', 2779),\n",
       " ('á', 2689),\n",
       " ('z', 2577),\n",
       " ('é', 2405),\n",
       " ('E', 1247),\n",
       " ('-', 1195),\n",
       " ('L', 1190),\n",
       " ('A', 1076),\n",
       " ('ñ', 934),\n",
       " ('P', 787),\n",
       " ('C', 758),\n",
       " ('M', 751),\n",
       " ('N', 737),\n",
       " ('S', 734),\n",
       " ('D', 618),\n",
       " ('ú', 599),\n",
       " ('\"', 522),\n",
       " ('T', 496),\n",
       " ('x', 490),\n",
       " ('R', 485),\n",
       " ('J', 454),\n",
       " ('Y', 424),\n",
       " (';', 384),\n",
       " ('B', 351),\n",
       " ('I', 329),\n",
       " ('O', 289),\n",
       " ('H', 287),\n",
       " ('U', 284),\n",
       " ('(', 278),\n",
       " (')', 277),\n",
       " (':', 263),\n",
       " ('V', 197),\n",
       " ('?', 173),\n",
       " ('¿', 170),\n",
       " ('Q', 128),\n",
       " ('F', 125),\n",
       " ('G', 107),\n",
       " ('k', 102),\n",
       " ('1', 81),\n",
       " ('2', 58),\n",
       " ('3', 47),\n",
       " ('4', 41),\n",
       " ('É', 40),\n",
       " ('w', 37),\n",
       " ('¡', 32),\n",
       " ('!', 32),\n",
       " ('5', 32),\n",
       " ('8', 22),\n",
       " ('6', 21),\n",
       " ('0', 18),\n",
       " ('9', 18),\n",
       " ('ü', 18),\n",
       " ('Ó', 16),\n",
       " ('’', 16),\n",
       " ('Á', 16),\n",
       " ('Í', 15),\n",
       " ('7', 15),\n",
       " ('K', 12),\n",
       " ('W', 9),\n",
       " ('Z', 8),\n",
       " ('Ú', 7),\n",
       " ('X', 4),\n",
       " ('è', 3),\n",
       " ('î', 3),\n",
       " ('â', 2),\n",
       " ('&', 2),\n",
       " ('Ñ', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(text_cleaned).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion para dar formato a la entrada/salida de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window_transform_text(text, window_size, step_size):\n",
    "    # containers for input/output pairs\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    # This is the number of iterations taking into acount the step_size and the window_size\n",
    "    N = int((len(text)-window_size)/step_size)\n",
    "    # Get inputs and outputs\n",
    "    for k in range(N):\n",
    "        i = k*step_size\n",
    "        inputs.append(text[i:i+window_size])\n",
    "        outputs.append(text[i+window_size])\n",
    "        \n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run your text window-ing function \n",
    "window_size = 100\n",
    "step_size = 3\n",
    "inputs, outputs = window_transform_text(text_train,window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = PLAGIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "output = \n",
      "\n",
      "--------------\n",
      "input = GIOS Y TRADUCCIONES\n",
      "I. EL HIJO DEL VAMPIRO\n",
      "PROBABLEMENTE todos los fantasmas sabían que Duggu Van\n",
      "er\n",
      "output = a\n"
     ]
    }
   ],
   "source": [
    "# print out a few of the input/output pairs to verify that we've made the right kind of stuff to learn from\n",
    "print('input = ' + inputs[0])\n",
    "print('output = ' + outputs[0])\n",
    "print('--------------')\n",
    "print('input = ' + inputs[1])\n",
    "print('output = ' + outputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this dictionary is a function mapping each unique character to a unique integer\n",
    "chars_to_indices = dict((c, i) for i, c in enumerate(chars))  # map each unique character to unique integer\n",
    "\n",
    "# this dictionary is a function mapping each unique integer back to a unique character\n",
    "indices_to_chars = dict((i, c) for i, c in enumerate(chars))  # map each unique integer back to unique character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '4': 13,\n",
       " '5': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " ';': 19,\n",
       " '?': 20,\n",
       " 'A': 21,\n",
       " 'B': 22,\n",
       " 'C': 23,\n",
       " 'D': 24,\n",
       " 'E': 25,\n",
       " 'F': 26,\n",
       " 'G': 27,\n",
       " 'H': 28,\n",
       " 'I': 29,\n",
       " 'J': 30,\n",
       " 'K': 31,\n",
       " 'L': 32,\n",
       " 'M': 33,\n",
       " 'N': 34,\n",
       " 'O': 35,\n",
       " 'P': 36,\n",
       " 'Q': 37,\n",
       " 'R': 38,\n",
       " 'S': 39,\n",
       " 'T': 40,\n",
       " 'U': 41,\n",
       " 'V': 42,\n",
       " 'W': 43,\n",
       " 'Y': 44,\n",
       " 'Z': 45,\n",
       " 'a': 46,\n",
       " 'b': 47,\n",
       " 'c': 48,\n",
       " 'd': 49,\n",
       " 'e': 50,\n",
       " 'f': 51,\n",
       " 'g': 52,\n",
       " 'h': 53,\n",
       " 'i': 54,\n",
       " 'j': 55,\n",
       " 'k': 56,\n",
       " 'l': 57,\n",
       " 'm': 58,\n",
       " 'n': 59,\n",
       " 'o': 60,\n",
       " 'p': 61,\n",
       " 'q': 62,\n",
       " 'r': 63,\n",
       " 's': 64,\n",
       " 't': 65,\n",
       " 'u': 66,\n",
       " 'v': 67,\n",
       " 'w': 68,\n",
       " 'x': 69,\n",
       " 'y': 70,\n",
       " 'z': 71,\n",
       " '¡': 72,\n",
       " '¿': 73,\n",
       " 'Á': 74,\n",
       " 'É': 75,\n",
       " 'Í': 76,\n",
       " 'Ó': 77,\n",
       " 'Ú': 78,\n",
       " 'á': 79,\n",
       " 'è': 80,\n",
       " 'é': 81,\n",
       " 'í': 82,\n",
       " 'ñ': 83,\n",
       " 'ó': 84,\n",
       " 'ú': 85,\n",
       " 'ü': 86,\n",
       " '’': 87}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars_to_indices)\n",
    "chars_to_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform character-based input/output into equivalent numerical versions\n",
    "def encode_io_pairs(text,chars, window_size,step_size):\n",
    "    num_chars = len(chars)\n",
    "    \n",
    "    # cut up text into character input/output pairs\n",
    "    inputs, outputs = window_transform_text(text,window_size,step_size)\n",
    "    \n",
    "    # create empty vessels for one-hot encoded input/output\n",
    "    X = np.zeros((len(inputs), window_size, num_chars), dtype=np.bool)\n",
    "    y = np.zeros((len(inputs), num_chars), dtype=np.bool)\n",
    "    \n",
    "    # loop over inputs/outputs and tranform and store in X/y\n",
    "    for i, sentence in enumerate(inputs):\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char not in chars_to_indices:\n",
    "                char = ' '\n",
    "            X[i, t, chars_to_indices[char]] = 1\n",
    "        out_char = outputs[i]\n",
    "        if out_char not in chars_to_indices:\n",
    "            out_char = ' '\n",
    "        y[i, chars_to_indices[out_char]] = 1\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use your function\n",
    "window_size = 100\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = encode_io_pairs(text_train, chars, window_size,step_size)\n",
    "X_validation, y_validation = encode_io_pairs(text_validation, chars, window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382953, 100, 88) (382953, 88)\n",
      "(350934, 100, 88) (350934, 88)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defino modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### necessary functions from the keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_rnn():\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    # First layer\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars))))\n",
    "    # Second layer\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    # initialize optimizer\n",
    "    # lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0\n",
    "    # optimizer = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # compile model --> make sure initialized optimizer and callbacks - as defined above - are used\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_deeper_no_rnn_dropout():\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)), return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars))))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_deeper_rnn():\n",
    "    # Model definition\n",
    "    print(\"input shape = \",(window_size,len(chars)))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)), return_sequences=True, \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(LSTM(200, input_shape =  (window_size,len(chars)),  \n",
    "                   dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_deeper_stateful_rnn(batch_size = 250):\n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, batch_input_shape =  (batch_size, window_size,len(chars)), return_sequences=True, \n",
    "                   dropout=0.2, recurrent_dropout=0.2, stateful=True))\n",
    "    model.add(LSTM(200, batch_input_shape =  (batch_size, window_size,len(chars)),  \n",
    "                   dropout=0.2, recurrent_dropout=0.2, stateful=True))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_deeper_rnn()\n",
    "model.load_weights('best_RNN_dropout_from_48.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_21 (LSTM)               (250, 100, 200)           231200    \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (250, 200)                320800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (250, 88)                 17688     \n",
      "=================================================================\n",
      "Total params: 569,688\n",
      "Trainable params: 569,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stateful cell\n",
    "statefull_train_size = int(len(X_train)/batch_size)*batch_size\n",
    "statefull_validation_size = int(len(X_validation)/batch_size)*batch_size\n",
    "X_train_stateful = X_train[:statefull_train_size]\n",
    "y_train_stateful = y_train[:statefull_train_size]\n",
    "X_validation_stateful = X_validation[:statefull_validation_size]\n",
    "y_validation_stateful= y_validation[:statefull_validation_size]\n",
    "\n",
    "batch_size = 250\n",
    "model = get_deeper_stateful_rnn(batch_size=batch_size)\n",
    "model.load_weights('best_RNN_dropout_from_stateful.hdf5')\n",
    "checkpointer = ModelCheckpoint(filepath='best_RNN_dropout_from_stateful_part_2.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 382750 samples, validate on 350750 samples\n",
      "Epoch 1/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 1.5686Epoch 00000: val_loss improved from inf to 1.67606, saving model to best_RNN_dropout_from_stateful_part_2.hdf5\n",
      "382750/382750 [==============================] - 565s - loss: 1.5686 - val_loss: 1.6761\n",
      "Epoch 2/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 1.6721Epoch 00001: val_loss did not improve\n",
      "382750/382750 [==============================] - 554s - loss: 1.6726 - val_loss: 2.1746\n",
      "Epoch 3/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 2.6786Epoch 00002: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 2.6789 - val_loss: 3.6104\n",
      "Epoch 4/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 4.5096Epoch 00003: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 4.5106 - val_loss: 5.6767\n",
      "Epoch 5/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 6.6553Epoch 00004: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 6.6557 - val_loss: 7.4478\n",
      "Epoch 6/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 8.2894Epoch 00005: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 8.2902 - val_loss: 9.1198\n",
      "Epoch 7/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2684Epoch 00006: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2687 - val_loss: 9.3606\n",
      "Epoch 8/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2804Epoch 00007: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2805 - val_loss: 9.3486\n",
      "Epoch 9/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2733Epoch 00008: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2736 - val_loss: 9.3460\n",
      "Epoch 10/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2676Epoch 00009: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2682 - val_loss: 9.3481\n",
      "Epoch 11/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2632Epoch 00010: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2635 - val_loss: 9.3416\n",
      "Epoch 12/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2603Epoch 00011: val_loss did not improve\n",
      "382750/382750 [==============================] - 553s - loss: 9.2603 - val_loss: 9.3434\n",
      "Epoch 13/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2569Epoch 00012: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2568 - val_loss: 9.3384\n",
      "Epoch 14/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2550Epoch 00013: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2549 - val_loss: 9.3382\n",
      "Epoch 15/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2523Epoch 00014: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2527 - val_loss: 9.3372\n",
      "Epoch 16/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2506Epoch 00015: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2507 - val_loss: 9.3388\n",
      "Epoch 17/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2490Epoch 00016: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2491 - val_loss: 9.3339\n",
      "Epoch 18/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2481Epoch 00017: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2483 - val_loss: 9.3352\n",
      "Epoch 19/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2462Epoch 00018: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2463 - val_loss: 9.3341\n",
      "Epoch 20/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2457Epoch 00019: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2459 - val_loss: 9.3362\n",
      "Epoch 21/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2435Epoch 00020: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2439 - val_loss: 9.3327\n",
      "Epoch 22/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2433Epoch 00021: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2430 - val_loss: 9.3344\n",
      "Epoch 23/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2419Epoch 00022: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2416 - val_loss: 9.3344\n",
      "Epoch 24/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2415Epoch 00023: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2414 - val_loss: 9.3355\n",
      "Epoch 25/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2408Epoch 00024: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2407 - val_loss: 9.3328\n",
      "Epoch 26/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2391Epoch 00025: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2394 - val_loss: 9.3318\n",
      "Epoch 27/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2390Epoch 00026: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2387 - val_loss: 9.3361\n",
      "Epoch 28/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2379Epoch 00027: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2377 - val_loss: 9.3340\n",
      "Epoch 29/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2378Epoch 00028: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2373 - val_loss: 9.3334\n",
      "Epoch 30/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2367Epoch 00029: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2367 - val_loss: 9.3359\n",
      "Epoch 31/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2362Epoch 00030: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2361 - val_loss: 9.3323\n",
      "Epoch 32/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2359Epoch 00031: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2358 - val_loss: 9.3352\n",
      "Epoch 33/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2354Epoch 00032: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2358 - val_loss: 9.3337\n",
      "Epoch 34/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2351Epoch 00033: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2350 - val_loss: 9.3334\n",
      "Epoch 35/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2343Epoch 00034: val_loss did not improve\n",
      "382750/382750 [==============================] - 550s - loss: 9.2346 - val_loss: 9.3352\n",
      "Epoch 36/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2347Epoch 00035: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2346 - val_loss: 9.3319\n",
      "Epoch 37/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2340Epoch 00036: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2340 - val_loss: 9.3315\n",
      "Epoch 38/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2343Epoch 00037: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2343 - val_loss: 9.3371\n",
      "Epoch 39/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2329Epoch 00038: val_loss did not improve\n",
      "382750/382750 [==============================] - 551s - loss: 9.2329 - val_loss: 9.3347\n",
      "Epoch 40/40\n",
      "382500/382750 [============================>.] - ETA: 0s - loss: 9.2333Epoch 00039: val_loss did not improve\n",
      "382750/382750 [==============================] - 552s - loss: 9.2335 - val_loss: 9.3331\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history_part_2 = model.fit(X_train_stateful, y_train_stateful, batch_size=batch_size, epochs=40, verbose = 1, \n",
    "                    validation_data = (X_validation_stateful, y_validation_stateful),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (250, 100, 200)           231200    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (250, 200)                320800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (250, 88)                 17688     \n",
      "=================================================================\n",
      "Total params: 569,688\n",
      "Trainable params: 569,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 382953 samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ed50e21793c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/egpu/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/egpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/egpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                                  \u001b[0;34m'a number of samples that can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                  \u001b[0;34m'divided by the batch size. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                                  str(x[0].shape[0]) + ' samples')\n\u001b[0m\u001b[1;32m   1401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: In a stateful network, you should only pass inputs with a number of samples that can be divided by the batch size. Found: 382953 samples"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "model = get_deeper_rnn()\n",
    "checkpointer = ModelCheckpoint(filepath='best_RNN_dropout_from_stateful.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n",
    "                    validation_data = (X_validation, y_validation),\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('history_deep_dropout_statefull', (loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCKRwFxGJQAp3EZEI9P8BOwRzn//S4LIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e7676d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Epochs Simple no dropout"
   ]
  },
  {
   "attachments": {
    "history_graph_20_epochs.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNX9//HXyR7IvgEJCWHf9yQiKiru1KVVW7VfrdYqUv229VdbbW2rtt+2Vm2tVVupC+5F3Kq4IooKiggBw74vgRAgC5ANss75/XEHCCEbMJlJZt7Px2MeM5l7MvfjdXjPyZlz7zHWWkRExL8E+boAERHxPIW7iIgfUriLiPghhbuIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPihEF/tOCkpyWZmZvpq9yIiXdLSpUtLrLXJbbXzWbhnZmaSm5vrq92LiHRJxpj89rTTsIyIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPghhbuIiB/qcuG+fncFf3pvDQdrG3xdiohIp9Xlwr1g3wGeWrCVvB37fV2KiEin1eXCPatPAgC52/b6uBIRkc6ry4V7bLdQBveIZkn+Pl+XIiLSaXW5cAfIyoxnWf4+GlzW16WIiHRKXTLcc/omUFlTz9pd5b4uRUSkU+qS4Z6VqXF3EZHWdMlwT4uLJDU2giXbNO4uItKcLhnuANl9E1iybS/WatxdRKSpLhvuWZkJFFXUsGPvQV+XIiLS6XTZcM/OjAdgicbdRUSO0WXDfVBKNDERIQp3EZFmdNlwDwoyZGUmKNxFRJrRZcMdnJOZNhdXUVpZ4+tSREQ6lS4d7jmH5rvrUgQiIkdpM9yNMenGmE+NMWuNMauNMT9rpW22MabBGHOlZ8ts3sjesYSFBOlkJhGRJkLa0aYeuMNau8wYEw0sNcbMtdauadzIGBMMPADM6YA6mxUeEszo3rE6mUlEpIk2e+7W2l3W2mXuxxXAWiCtmaY/Ad4AijxaYRuyMhNYtbOMA7X13tytiEindlxj7saYTGAs8HWT59OA7wDT2/j9qcaYXGNMbnFx8fFV2oKczATqXVaLd4iINNLucDfGROH0zG+31ja9HOMjwF3W2lbXvrPWPmmtzbLWZiUnJx9/tc0YlxGPMZCroRkRkcPaM+aOMSYUJ9hftta+2UyTLOAVYwxAEjDFGFNvrX3LY5W24PDiHfpSVUTksDbD3TiJ/Qyw1lr7cHNtrLV9G7V/DnjXG8F+SHZmAm8uK6C+wUVIcJee3Ski4hHtScLTgOuAycaYPPdtijFmmjFmWgfX1y5ZmfFU1TawbneFr0sREekU2uy5W2u/AEx7X9Bae8PJFHQist0nMy3eupcRabHe3r2ISKfjF2MYqXGRpMVFkpuvcXcREfCTcAfnEsBLtu3T4h0iIvhRuGdlJlBcUcP2vQd8XYqIiM/5Tbjn9D0y7i4iEuj8JtwHJEcRGxmqk5lERPCjcA8KMmT1iWeJvlQVEfGfcAfI7pvAluIqSrR4h4gEOP8Kd/ei2RqaEZFA51fhPiJNi3eIiICfhXt4SDBj0uN0ETERCXh+Fe7gDM2sKizX4h0iEtD8LtyzMhNocFnytmvxDhEJXH4X7uP7OIt3LNbQjIgEML8L95iIUIb0jNGMGREJaH4X7uCMuy/bvo/6BpevSxER8Qk/DfcEDtQ2sGZX06VeRUQCg1+Ge5b7ZKYlGpoRkQDll+HeKzaS3vGROplJRAKWX4Y7QE5mAku27dXiHSISkPw23LMyEyiprGVbqRbvEJHA47fhnn143F1DMyISeLpeuLtcsOmTNpsNSIkivluoxt1FJCB1vXD/5kV46XLYPK/VZsYYxvdJ0IwZEQlIXS/cR18N8X3hw19DQ+sXB8vOjGdrSRXFFVq8Q0QCS9cL95BwuOBPULwOcp9ptWlWprNo9lItvSciAabNcDfGpBtjPjXGrDXGrDbG/KyZNv9jjFnhvi00xozumHLdBk+BfmfDp3+CqtIWm41MiyU8JIjFWzU0IyKBpT0993rgDmvtUGACcJsxZliTNluBM621o4D/A570bJlNGAMX3g81lU7AtyAsJIgx6XHkqucuIgGmzXC31u6y1i5zP64A1gJpTdostNYe6h4vAnp7utBjpAyF7Jtg6bOwe1WLzbIzE1hdWE5VjRbvEJHAcVxj7saYTGAs8HUrzX4EfNDC7081xuQaY3KLi4uPZ9fNO/vXEBEHH/4KWjgTNbuvs3jHN1q8Q0QCSLvD3RgTBbwB3G6tbfZyi8aYs3HC/a7mtltrn7TWZllrs5KTk0+k3qNFxsPk38C2BbB2drNNxmXEEWR0MpOIBJZ2hbsxJhQn2F+21r7ZQptRwNPAZdbalr/l9LTxP4QeI2DOb6Hu4DGbow8t3qFxdxEJIO2ZLWOAZ4C11tqHW2iTAbwJXGet3eDZEtsQFAwX/gXKtsPCx5ttktM3gWX5+6nT4h0iEiDa03M/DbgOmGyMyXPfphhjphljprnb3AMkAv9yb8/tqIKb1fcMGHYZfPEwlO08ZnNWZjwH6xpYU6jFO0QkMIS01cBa+wVg2mhzE3CTp4o6Ief9H2yYAx/fC1c8fdSmbPfJTEu27WV0epwvqhMR8aqud4ZqS+L7wMSfwsrXYPuiozb1iIkgI6GbvlQVkYDhP+EOcPrtEJ0KH9zpXD2ykazMeHK37dPiHSISEPwr3MO6w3l/gF3LIe/lozZlZyZQWlXL1pIqHxUnIuI9/hXuACOvhPQJ8Mnvobrs8NOHxt1zdQlgEQkA/hfuxsBFf4GqEpj/0OGn+yd3J75bKIs17i4iAcD/wh0gdSyMvRYWTYeSTYCzeEdWZoJWZhKRgOCf4Q5wzj0QGglz7j78VE5mAttKD1BUUe3DwkREOp7/hntUCpx5J2ycAxvnAs6MGdC4u4j4P/8Nd4CcWyBxgLMkX30tw1NjiQgN0nx3EfF7/h3uIWFwwf1QuhEWP0lYSBBj0+PVcxcRv+ff4Q4w6HwYcB58/gBUFpOdGc/qwjIqqut8XZmISIfx/3AHuODPUHcA5v2BMwen4LLw6CcbfV2ViEiHCYxwTx4Ep0yDZS8yPjSfaydk8NSCrXyxscTXlYmIdIjACHeASb+Ebonw4a/4zUVD6Z/cnTtey2NfVa2vKxMR8bjACffIOGfu+/aviNzwFv+4eix7q2q5+78rdTExEfE7gRPu4Jy12nMUzL2HEfEN3HH+YD5YtZvXcgt8XZmIiEcFVrgHBcO3/uZcd+apyUwdUsep/RK5753VbNPVIkXEjwRWuAOk58AN70FtFUEzzuPxnFJCggw/m5WnNVZFxG8EXrgDpGfDzfMgrg+Jb1/LzFF5LN+xj8c0PVJE/ERghjtAXDrc+CEMnsLwFX9mZs9XmP7pOl2aQET8QuCGO0B4FHzvRTj955y6/x1eiXyIe15ZQLnOXhWRLi6wwx0gKAjOvRe+82/GsJ4nDt7JP19939dViYicFIX7IaOvJuiGd0kJq+G2zdP46qPXfF2RiMgJU7g3lnEKYdM+Y29ICtkLp7L/s8d9XZGIyAlRuDcRkphJ8E1zWWDHEvfZb3C9+3No0Bi8iHQtbYa7MSbdGPOpMWatMWa1MeZnzbQxxphHjTGbjDErjDHjOqZc70jvlULpJc8yvf4SgnKfgZeugIO6BryIdB3t6bnXA3dYa4cCE4DbjDHDmrS5CBjovk0FnvBolT5wxfgMVg77OXfWT8OVvxCePvfwYtsiIp1dm+Furd1lrV3mflwBrAXSmjS7DHjBOhYBccaYXh6v1ouMMfz52yNZ0P18bg//A/bAPnh6Mmz5zNeliYi06bjG3I0xmcBY4Osmm9KAHY1+LuDYDwCMMVONMbnGmNzi4uLjq9QHYruF8rfvjead/X14qM8TEJ0KL14Oi58CXUlSRDqxdoe7MSYKeAO43Vpb3nRzM79yTPpZa5+01mZZa7OSk5OPr1Ifmdg/iamT+vGvvHo+Oe0lGHAuvP8LmHUtVOzxdXkiIs1qV7gbY0Jxgv1la+2bzTQpANIb/dwbKDz58jqHO84bzIi0GH4xewtF33oWzr0PNs6Ff50CK15VL15EOp32zJYxwDPAWmvtwy00mw38wD1rZgJQZq3d5cE6fSosJIhHrhrLwboGfvHmalwTb4dpCyBxALx5M7zyfajY7esyRUQOa0/P/TTgOmCyMSbPfZtijJlmjJnmbvM+sAXYBDwF3Nox5frOgJQofvutYczfUMzzX22D5MFw4xw4/4+weR78MwfyZqoXLyKdgvHVEnNZWVk2NzfXJ/s+UdZabn4hl/kbS3jxxhxO6ZfobCjZBG/fBjsWwcAL4JJHICbVt8WKiF8yxiy11ma11U5nqB4HYwwPXDGKjIRuXP/sYr7YWOJsSBoAP3wfLrgfts6Hf06Ab15SL15EfEbhfpwSo8J5ZeoEMhO7c+PzS/h0fZGzISgYTr0Vfvwl9Bju9ORfvhLKtD6riHifwv0EJEWFM/PmCQzqEcUtLyxl7ppGUyIT+zvL+F30EOQvdHrxS59XL15EvErhfoLiu4fx8k0TGJoaw49fWsr7KxtNDgoKglOmwo8XQuoYeOen8OJ3YP923xUsIgFF4X4SYiNDeelHOYxJj+MnM7/h7bydRzdI6As/mA3f+hvsWAz/OhVyZ6gXLyIdTuF+kqIjQnn+xhyyM+O5fVYer+XuOLpBUBBk3wS3fgVp4+Hd/wcvXAp71vimYBEJCAp3D+geHsKzN+Rw+oAkfvn6Cv7zdTPDL/F94Advw8WPQGEeTD8N3roNynYe21ZE5CQp3D0kMiyYp36QxeQhKdz935U89+XWYxsZA1k/hJ8th1N+DCtfhcfGwdx7dL14EfEohbsHRYQGM/3a8VwwvAf3vbOGJ+dvbr5htwS48M/wv7kw7DL48lH4xxjnvq7au0WLiF9SuHtYWEgQj39/HBeP6sWf31/H4/M2ttw4vg9c/iTcMt8Zj5/7O3g8y7mMgavBe0WLiN9RuHeA0OAgHrlqDJePTeOvH23g4Y/W0+plHnqNguvedMbkuyXCW9Ng+hmw4SPNrBGRE6Jw7yAhwUE89N3RXJWVzqPzNvGXD9e1HvAA/c6Cmz+FK2dAXRX857vw/CVQsNQbJYuIH1G4d6DgIMP9l4/k2gkZ/PvzLfzh3TVtB3xQEIy4Am5bAhc9CEVrnOX9Xr0eSlsYwxcRaSLE1wX4u6Agw/9dNoKw4GBmfLmVugYXf7h0BEFBzS1e1UhIGJxyC4y+BhY+Bl89DuvehfE3wJl3QVSKV+oXka5J4e4Fxhh+d/FQwkKCmP75ZurqLX/6zghCgtvxh1NEDEz+jXMi1OcPQO6zzheuY691wj+xf8f/B4hIl6NhGS8xxnDXhYP52TkDmZW7g+ufXczeqtr2v0B0D7j4YbhtMQy9xLmMwWPj4T9XwZbP9MWriBxFi3X4wKu5O/jtW6tIjgrniWvHMap33PG/SMVuWPKME/IHSiBlGJwyDUZ9D0IjPV+0iHQK7V2sQ+HuIysLypj20lKKK2v442Uj+F52etu/1Jy6alj1Bix6AvashMgE5yzY7Ju0GpSIH1K4dwF7q2r56cxv+GJTCd8/JYN7LxlGeEjwib2YtbDtC/h6Oqx7z1k8ZNi3YcKt0Hu8ZwsXEZ9RuHcRDS7LXz9azxOfbWZMehxPXDuOXrEnOayydyssfgqWvQC1FdA7Gyb8GIZeCsGhnilcRHxC4d7FfLhqF3e8upzIsGAeu2Ycp/ZPPPkXramAvP84Qzb7tkJ0KuTc7Eyn7JZw8q8vIl6ncO+CNhVVMPXFpeSXHuDXFw3hR6f3xZg25sO3h8sFGz+CRf+CrZ9DSIRzwbIx/wOZZzgnTolIl6Bw76Iqquv4xWvLmbN6DxeP6sWDV46iW5gHT0fYsxqWPA0r34CaMojLcEJ+9DXOhcxEpFNTuHdh1lqe+Hwzf52znoEp0Uy/bjx9k7p7did1B2Htu5D3Emz5HLDQ90zn5Kihl2g6pUgnpXD3Aws2FvOTmd/Q4LI8ctUYzhnao2N2tH+7c9Zr3suwPx/CY5zr24y91rkUsSeGhkTEIzwW7saYGcDFQJG1dkQz22OBl4AMnMsZ/NVa+2xbO1a4t8+OvQf48ctLWbWznJ+eM5DbzxnY9nVpTpTLBflfwDcvw5q3of4gJA9xhm1GXeWcJSsiPuXJcJ8EVAIvtBDudwOx1tq7jDHJwHqgp7W21XPrFe7tV13XwG/fWsXrSws4e3Ayj1w1lthuHTylsbocVr/pBH3BYjDBMPB8pzc/6AJNqRTxkfaGe5vf1Flr5xtjMltrAkQbZ1pHFLAXqG9nndIOEaHBPHTlKMakx/H7d1ZzyeNf8PerxjC+T3wH7jTGmTI5/gYo3uCMzS9/BTZ84CwoMvACGHgu9Dtb0ypFOqF2jbm7w/3dFnru0cBsYAgQDVxlrX2vhdeZCkwFyMjIGJ+fn3/ChQeqpfn7+OnMbygsO8iPTuvLHecPJjLsBM9qPV4N9bD5E1gxCzbPcxb1NkGQlgUDznVuqWM1tVKkA3n0C9U2wv1K4DTg50B/YC4w2lpb3tpraljmxFXW1HP/+2t5+evtZCZ248ErR5PT18u9Z1cD7FwGm+bCpo+dx1inV99/Mgw4z7mPSvZuXSJ+zpvh/h7wF2vtAvfP84BfWWsXt/aaCveTt3BTCXe9uYKCfQe5/tRM7rxwsGfnxB+PqhLY/KkT9Js+dq5UCdBrDAw8z+nVp2VBsJYQEDkZ3gz3J4A91tr7jDE9gGU4PfeS1l5T4e4ZVTX1PDRnPc8t3EZGQjceuGKUZy5dcDJcLti9HDa6g75gMVgXRMQ6Y/QDzoWMU52FRjTNUuS4eHK2zEzgLCAJ2APcC4QCWGunG2NSgeeAXoDB6cW/1NaOFe6e9fWWUu58YwX5pQe4dkIGv7poKFHhnaSXfHCfs6DIpo9h0ydQsct5PiLOmUffO8u5uFnaeH05K9IGncQUgA7WNvDXj9Yz48utpMZG8sAVozh9YJKvyzqatVC8DgqWQEGucyte6/TsARL6OcM3vbOdSxX3GOmsJysigMI9oC3N38svX1vBlpIqrslJ5+4pQ4mO6MTz0msqofAb2Jl7JPArdzvbgsOh12ind3+olx/XR8M5ErAU7gGuuq6Bv8/dwFMLttAzJoL7rxjFmYO6yMwVa6F8pzvol8DOpVCY55wxC9A92Qn6tCxIG+fcIjtwzr9IJ6JwFwC+2b6PO19fwcaiSr47vje/vXgYsZGduBffkoY6KFpzpGe/cymUbMA5hw5IHOAOfHfo9xwBIeE+LVmkIyjc5bCa+gYe/WQj0z/fQlJUGPdfPpLJQ/zgOjHVZe7hnKXOPPvGwzlBodBz5JHhnLTxkNBfJ1hJl6dwl2OsLCjjl68vZ93uCi4a0ZPffGsoveO7+bosz7EWygvdYZ/rBH7hN1Bb6WyPiIVU9zBObDpEpUD3FOc+KkWXOZYuQeEuzaqtd/HUgi08Pm8TFsuPzxzALWf2IyLUS5cw8DZXAxSvbxT4S2HPGrANx7YNi3bOqI3q4YzrNw3/7ilHtuuDQHxE4S6tKtx/kD+9v5b3VuwiPSGS331rGOcN6+GZZf06u/paqCqCyiKoKnbuK/cceVxV7PxcWQTV+5t/jagezrTNhP6Q2O/I44R+EB7l3f8eCSgKd2mXhZtLuG/2ajbsqWTSoGTuvWQY/ZMVTofV1x4J+8MfBLth7zbYuwX2bna2NRbV40jQJzYKfQW/eIDCXdqtrsHFi1/l8/e5G6iub+DG0/vyk8kDO88Zrp1dTQXs3eoEfenmox9XFR3dNqqnE/KxvSEmFWLSIKbXkcfdkyHIT4fIxCMU7nLciitqePDDdby2tIAeMeHcPWUol45ODYyhmo5SU+H08Es3u3v67lv5TijfBa66o9sHhUB0L+d2OPxTj/4giO6lxVICmMJdTtiy7fu4b/ZqVhSUkZOZwH2XDmdYaoyvy/I/Lpdz9cxDQV++05ntU14IFYVHHtcdOPZ3TbDTwzdBjW7Bzpm7JqjJtkOPzZHnw6Kc2UMRMe77OGft3IjYJs/HHnk+PKZrTiV1NTgfsjXlzgpjNRXOh6q17steuO8tjX5uus0evQ3cZ0mb1u9NUJPncO7jM50L550AhbucFJfL8mruDh6cs579B2q5dkIffn7eIOK66TovXmWt86VueeGRD4CK3dBQ4w4dlxNeh8LHNhx5vqVtrnqorXLOE6gud9+XQV1VG8UYCI92Qj44tNEHSKMPkqAmHyjHfAC5nwsKda4ZFNz0Furch4QfeRwcfvTzQSFQd9AJ68OB3cx9TYXzuLbCK/+rjstpt8N5vz+hX1W4i0eUHajj4bnreXFRPrGRodx54RC+l5VOcEct0i2+01DnDsT9xwZ/TfnRz7nqGn14uJr5QGn8YdJ4e4Oz3VXn7K+h1vnSuqHJzXUcK3WGRLj/uog58uETEQPh7r9Amm4Lj3Y+KA79NdO4d33U48Y/BzXpmePuwdv23Td9LroXxPc5of9NCnfxqDWF5dw3ezWLt+1lZFosd08Z6vvrxov/crmcD4D6miMfAg2NHodEHBkqCrCrhircxeOstcxeXsj9769jd3k1Zw5K5pcXDGZEWqyvSxMJGO0N9y747Yj4ijGGy8ak8dkvz+LuKUPI27Gfix/7gp/O/IZtJW2N14qIN6nnLies7GAdT87fzIwvtlHX4OLqnHR+es5AUqIjfF2aiN/SsIx4TVF5NY/O28gri3cQGhzEjadncsuZ/YnpzAuEiHRRCnfxum0lVTw8dwOzlxcS1y2UW8/qzw9OzfTfi5KJ+IDCXXxm1c4yHpqzns83FNMrNoLbzx3IFeN6ExKsr3hETpa+UBWfGZEWy/M35jDz5gn0iIngrjdWcsEj8/lw1S581ZkQCTQKd+kwp/ZP5L+3TuTf143HGMO0l5bx7X8tZOGmEl+XJuL3NCwjXtHgsry5rIC/z91AYVk14zLimDqpP+cP60GQznYVaTeNuUunVF3XwKwlO3j6iy3s2HuQfknduemMflw+Lk1fvIq0g8JdOrX6Bhcfrt7Nk/O3sKKgjKSoMK4/NZPrTu2ji5OJtMJj4W6MmQFcDBRZa0e00OYs4BEgFCix1p7Z1o4V7gLOJQ0WbdnLv+dv5rP1xUSGBnNVdjo/Or0v6Ql+tHi3iId4MtwnAZXAC82FuzEmDlgIXGit3W6MSbHWFjVt15TCXZpav7uCJ+dvYfbynbgsTBnZi1sm9dO1a0Qa8eiwjDEmE3i3hXC/FUi11v72eApUuEtLdpdV8+yXW/nP19upqKlnYv9Epk7qx5mDkrUqlAQ8b4b7oeGY4UA08A9r7QstvM5UYCpARkbG+Pz8/Db3LYGrvLqOmV9v59kvt7G7vJohPaO5+Yx+XDI6lbAQzeKVwOTNcH8cyALOASKBr4BvWWs3tPaa6rlLe9XWu5i9vJCn5m9h/Z4KesZEcE1OBt/L7k2v2EhflyfiVe0Nd08sb1+A8yVqFVBljJkPjAZaDXeR9goLCeLK8b25Ylwan20oZsYXW/n7xxv4xycbOGtwCldnpzN5SIoubyDSiCfC/W3gcWNMCBAGnAL83QOvK3IUYwxnD07h7MEpbC89wKzc7byWW8DUdUWkRIfz3azeXJ2doVk2IrRvtsxM4CwgCdgD3Iszxo61drq7zS+BHwIu4Glr7SNt7VjDMuIJ9Q0u5q0r4pUlO/hsfREuC6cPSOKanAzOG9ZDY/Pid3QSkwScwv0HeS23gFdzd7Bz/0ESu4dxxfjeXJWdTv/kKF+XJ+IRCncJWA0uy/yNxbyyeDufrC2i3mXJ6ZvA1dnpTBnZS5c5kC5N4S4CFFVU8/rSAmYt2UF+6QFiIkL4ztg0Lh/Xm1G9YzVvXrochbtIIy6XZdGWUmYu2cGcVbupbXCRkdCNS0b34pLRqQzpGePrEkXaReEu0oKyA3XMWb2bd1YU8uWmElwWBvWI4pJRqVw8OpW+Sd19XaJIixTuIu1QXFHDh6t28c7yXSzetheAkWmxXDK6FxePSiU1TidJSeeicBc5ToX7D/Leil28s6KQFQVlAGRnxnPJ6FQuGtGL5OhwH1coonAXOSnbSqp4d0Uh7yzfxfo9FQQZmNg/iUtHp3LB8J7Edgv1dYkSoBTuIh6yfncF7ywv5J0VheSXHiA02HBK30TOHpLCOUNSyNQYvXiRwl3Ew6y1rNxZxnsrdvHJuiI2FVUC0C+pO2cPSWHykBSyMxN0Vqx0KIW7SAfbXnqAeev2MG99MYs2l1Lb4CIqPITTByQxeWgKZw1OJiU6wtdlip9RuIt40YHaer7cVOqE/boi9pTXADCqdyxnD3Z69SPTYgkK0klTcnIU7iI+Yq1lza5yPl1XxCfrisjbsR9rISkqnLMHJzN5SAqnDUwiJkJfysrxU7iLdBKllTV8vqGYeeuK+HxDMRXV9QQHGcamxzFpUDJnDExiVO84gtWrl3ZQuIt0QnUNLpbl72P+xmIWbCxh5c4yrIXYyFBOH5DEpEFJnDEwWSdPSYsU7iJdQGllDV9sKmHBxhIWbCw+PFY/ICWKSQOTOWNQEhP6JhIZpitZikPhLtLFWGvZsKeS+RuKmb+xmK+37qW23kVYcBDZfeOZNDCZSYOSGdIzWlezDGAKd5Eurrquga+37mWBO+w37HHm1SdHh3Na/0Qm9k/i1P6JWlYwwHhzgWwR6QARocGcOSiZMwclA7C7rPrwWP0Xm0p4K68QgPSESCb2S2LigERO7ZdISozm1ot67iJdkrWWjUWVfLW5lIWbS/hqcynl1fUA9E/uzsT+SUzsn8iEfonEdw/zcbXiSRqWEQkgDS7L2l3lLNxcwsLNpSzeupcDtQ0YA0N7xjCxfyITBySSnZlAtObXd2kKd5EAVtfgYkXBfhZuKmXh5lKWbt9Hbb2L4CDDqN6x5GQmML5PPOP7xJMYpUsZdyUKdxE5rLqugWX5+1i4uZSvtpSysqCM2gYX4Fz4bHyfeLIy4xnfJ4H+yd01G6cT0xeqInJYRGgwEwckMXFAEuCE/cqdZeRu28fS/L18vHYPry0tACC+W6i7V59AVmY8I9Oj8geyAAAKlUlEQVRiiQjVPPuuRuEuEoAiQoPJzkwgOzMB6I+1ls3FVSzN3+sO/H18vLYIgLDgIEb2jiXLPYwT6EM520qq6Bkb0ek/8DQsIyLNKq2sYWm+E/S5+fuOGsrpk9iN0b3jGJMex5iMOIb1iun0YXey9lXV8pcP1jErdwcj02KZcUO2T5Ze9NiYuzFmBnAxUGStHdFKu2xgEXCVtfb1tnascBfpWqrrGli1s4zc/H0s37GfvB372VVWDUBosGForxjGpMc5oZ8RR9/E7n5xiWOXy/L60gLu/2AtFdX1fHtsGu+uKKRHTAQv3JhDn0TvrsTlyXCfBFQCL7QU7saYYGAuUA3MULiLBIY95dXkuYN++Y79rCgoo7LGmW8fExHC6PS4owI/qYsN56zbXc5v/7uK3Px9ZGfG88dvj2Rwz2iWbd/Hjc8tISTI8OwNOYzsHeu1mjw6W8YYkwm820q43w7UAdnudgp3kQDU4LJsLq48HPh52/ezfk8FDS4nZ9LiIhmTEceotFiGp8YyPDWmU55kVVVTzyMfb2DGl9uIiQjh11OGcuW43kf9JbKpqJLrZyxm/4Fapl83njMGJnulNq+FuzEmDfgPMBl4hlbC3RgzFZgKkJGRMT4/P7/NfYtI13awtoFVhWXkbd9PXoET+Dv3Hzy8PS0ukhFpMYxIjWVEmhP4vrqEgrWWOat38/t31rCrrJprctK584IhLX4A7Smv5voZi9lUVMlfvzuab49N6/AavTkV8hHgLmttQ1tzY621TwJPgtNz98C+RaSTiwxrPDPHsa+qltWF5awqLGN1YTmrd5YxZ/Wew9uTo8MZkRrjDvtYRqTFkBYX2aHz77eXHuDe2av4dH0xQ3vF8Pj3xzG+T3yrv9MjJoJZt5zK1BdyuX1WHiWVNdx0Rr8Oq/F4eKLnvhU4dMSTgAPAVGvtW629poZlRKSxiuo61u6qYNXOMlYVlrGmsJyNRZWHh3RiI0MP9/CHpcYwPDWWvkndT3oFq5r6Bp78fAuPf7qJkCDD/ztvEDdMzCQkOKjdr1Fd18DPX83j/ZW7ufmMvvz6oqEd9mWy13ru1tq+jXb6HM6HQKvBLiLSVHREKDl9E8jpe6SHX13XwLrdTuCvLixj1c5ynv1y2+EpmZGhwQzpFc3w1BiG9XKGdAb3jG73tMwvN5Xwu7dXsaW4iikje3LPxcPpGXv8Q0IRocE8ds04kqJW89SCrRRX1PDglaMJC2n/B4SntRnuxpiZwFlAkjGmALgXCAWw1k7v0OpEJKBFhAY7c+nT4w4/V1vvYnNxpTOc4+7hv51XyEuLtgMQHGTon9yd4amxDOsV4wR/agxx3Y6MmxdVVPPHd9cye3khGQndeO6H2Zw1OOWkag0OMvz+0uH0iIngoTnrKa2q5YlrxxMV7ptzRXUSk4h0edZaduw9yJpdzhj+msJyVheWs7u8+nCbtLhIhqXG0Ds+ktdzC6ipdzHtrP7celZ/j5+A9WruDn795kqG9Yrx+MlOunCYiAS80soa1uwqd/fyy1lTWMbWkipOG5DE7y8dTr/kqA7b97x1e7j15WUeP9lJ4S4i0oz6BtdxfVl6MjriZKf2hrvvRvtFRHzAW8EOMC4jntenTSQ8JJirn/yKBRuLvbZvhbuISAcakBLFm7dOJD2hGz98dglvfbPTK/tVuIuIdLBDJzuN7xPP7bPyePbLrR2+T4W7iIgXxEaG8vyNOVw6OpXMpI6/kqQW6xAR8ZKI0GAevWasV/alnruIiB9SuIuI+CGFu4iIH1K4i4j4IYW7iIgfUriLiPghhbuIiB9SuIuI+CGfXRXSGFMMnOgK2UlAiQfL8bTOXh90/hpV38lRfSenM9fXx1qb3FYjn4X7yTDG5Lbnkpe+0tnrg85fo+o7Oarv5HT2+tpDwzIiIn5I4S4i4oe6arg/6esC2tDZ64POX6PqOzmq7+R09vra1CXH3EVEpHVdtecuIiKt6NThboy50Biz3hizyRjzq2a2hxtjZrm3f22MyfRibenGmE+NMWuNMauNMT9rps1ZxpgyY0ye+3aPt+pz73+bMWale9/HrEZuHI+6j98KY8w4L9Y2uNFxyTPGlBtjbm/SxuvHzxgzwxhTZIxZ1ei5BGPMXGPMRvd9fAu/e727zUZjzPVerO8hY8w69//D/xpj4lr43VbfDx1Y333GmJ2N/j9OaeF3W/333oH1zWpU2zZjTF4Lv9vhx8+jrLWd8gYEA5uBfkAYsBwY1qTNrcB09+OrgVlerK8XMM79OBrY0Ex9ZwHv+vAYbgOSWtk+BfgAMMAE4Gsf/r/ejTN/16fHD5gEjANWNXruQeBX7se/Ah5o5vcSgC3u+3j343gv1Xc+EOJ+/EBz9bXn/dCB9d0H/KId74FW/713VH1Ntv8NuMdXx8+Tt87cc88BNllrt1hra4FXgMuatLkMeN79+HXgHGOM8UZx1tpd1tpl7scVwFogzRv79qDLgBesYxEQZ4zp5YM6zgE2W2tP9KQ2j7HWzgf2Nnm68fvseeDbzfzqBcBca+1ea+0+YC5woTfqs9Z+ZK2td/+4COjt6f22VwvHrz3a8+/9pLVWnzs7vgfM9PR+faEzh3sasKPRzwUcG56H27jf3GVAoleqa8Q9HDQW+LqZzacaY5YbYz4wxgz3amFggY+MMUuNMVOb2d6eY+wNV9PyPyhfHr9Delhrd4HzoQ6kNNOmsxzLG3H+GmtOW++HjvS/7mGjGS0Ma3WG43cGsMdau7GF7b48fsetM4d7cz3wplN72tOmQxljooA3gNutteVNNi/DGWoYDTwGvOXN2oDTrLXjgIuA24wxk5ps7wzHLwy4FHitmc2+Pn7HozMcy98A9cDLLTRp6/3QUZ4A+gNjgF04Qx9N+fz4AdfQeq/dV8fvhHTmcC8A0hv93BsobKmNMSYEiOXE/iQ8IcaYUJxgf9la+2bT7dbacmttpfvx+0CoMSbJW/VZawvd90XAf3H+9G2sPce4o10ELLPW7mm6wdfHr5E9h4ar3PdFzbTx6bF0f4F7MfA/1j1A3FQ73g8dwlq7x1rbYK11AU+1sF9fH78Q4HJgVkttfHX8TlRnDvclwEBjTF937+5qYHaTNrOBQ7MSrgTmtfTG9jT3+NwzwFpr7cMttOl56DsAY0wOzvEu9VJ93Y0x0Yce43zptqpJs9nAD9yzZiYAZYeGH7yoxd6SL49fE43fZ9cDbzfTZg5wvjEm3j3scL77uQ5njLkQuAu41Fp7oIU27Xk/dFR9jb/H+U4L+23Pv/eOdC6wzlpb0NxGXx6/E+brb3Rbu+HM5tiA8y36b9zP/QHnTQwQgfPn/CZgMdDPi7WdjvNn4wogz32bAkwDprnb/C+wGueb/0XARC/W18+93+XuGg4dv8b1GeCf7uO7Esjy8v/fbjhhHdvoOZ8eP5wPml1AHU5v8kc43+N8Amx03ye422YBTzf63Rvd78VNwA+9WN8mnPHqQ+/DQzPIUoH3W3s/eKm+F93vrxU4gd2raX3un4/59+6N+tzPP3fofdeordePnydvOkNVRMQPdeZhGREROUEKdxERP6RwFxHxQwp3ERE/pHAXEfFDCncRET+kcBcR8UMKdxERP/T/AS/itSZ3xeuEAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![history_graph_20_epochs.png](attachment:history_graph_20_epochs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 101\n",
    "X_test, _ = encode_io_pairs(text_validation[:test_size],chars, window_size,step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXOLOTL\n",
      "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
      "Iba a verlos al acuario del Jardín des\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 100, 88)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_validation[:test_size])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALPHASIZE = len(chars)\n",
    "def sample_from_probabilities(probabilities, topn=ALPHASIZE):\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(ALPHASIZE, 1, p=p)[0]\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))\n",
    "\n",
    "def chars_to_one_hot(sentence, chars):\n",
    "    num_chars = len(chars)\n",
    "    size = max(len(sentence),window_size)\n",
    "    X = np.zeros((1, size, num_chars), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        if char not in chars_to_indices:\n",
    "            char = ' '\n",
    "        X[0, t + size - len(sentence), chars_to_indices[char]] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 50\n",
    "X_text_str = text_validation[:test_size]\n",
    "chars_to_one_hot(X_text_str[0:], chars).astype(int).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escribir sobre nosotros, creyendo imaginar un\n",
      "cuento va a escribir todo esto sobre los axolotl.\n",
      "LA NOC\n"
     ]
    }
   ],
   "source": [
    "## Cuento nuevo\n",
    "print(text_validation[11350:11452])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen resultados distintos entrenamientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una sola epoch, modelo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350912/350934 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2390101701531582"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple = get_simple_rnn()\n",
    "model_simple.load_weights('best_RNN_textdata_weights_01_epochs_step_1_epochs_valid.hdf5')\n",
    "model_simple.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Epochs, modelo simple\n",
    "**Overfitting a partir de aca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 317s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6993086159786712"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.load_weights('best_RNN_textdata_weights_20_epochs_step_1_epochs_valid.hdf5')\n",
    "model_simple.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28 epochs, modelos deep sin dropout en LSTM pero si entre LSTMs\n",
    "**Overfitting a partir de aca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 673s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6121161029150335"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_ndo = get_deeper_no_rnn_dropout()\n",
    "model_deep_ndo.load_weights('best_RNN_textdata_weights_28_epochs_step_1_epochs_valid_2layers.hdf5')\n",
    "model_deep_ndo.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 epochs, modelo deep con dropout en LSTM\n",
    "**Podría seguirla entrenando** Ultima posicion que disminuye: 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 681s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5581404215710672"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_50_epochs.hdf5')\n",
    "model_deep_rnn.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 epochs desde el epoch 48 del anterior, modelo deep con dropout en LSTM\n",
    "**Podría seguirla entrenando** Ultima posicion que disminuye: 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350934/350934 [==============================] - 689s   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5403717923841169"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_from_48.hdf5')\n",
    "model_deep_rnn.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    print(a)\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 88)\n",
      "1.0\n",
      "[  1.09773895e-16   9.99987841e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.61068178e-36   1.58657088e-27\n",
      "   4.36446444e-28   1.89791612e-38   0.00000000e+00   5.03110990e-40\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   5.25753109e-33\n",
      "   0.00000000e+00   1.21833045e-05   4.51834104e-27   9.19604354e-27\n",
      "   0.00000000e+00   2.07892436e-40   0.00000000e+00   1.15623589e-25\n",
      "   1.73158184e-18   5.81557357e-29   1.54002701e-42   3.50324616e-44\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   7.00649232e-44   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "sum(pvals[:-1]) > 1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-f93bb1863ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_from_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mnew_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_to_chars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mX_text_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_text_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_char\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-ce0da1d84d9c>\u001b[0m in \u001b[0;36msample\u001b[0;34m(a, temperature)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multinomial\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sum(pvals[:-1]) > 1.0"
     ]
    }
   ],
   "source": [
    "#model = get_simple_rnn()\n",
    "#model.load_weights('best_RNN_textdata_weights_01_epochs_step_1_epochs_valid.hdf5')\n",
    "#model.load_weights('best_RNN_textdata_weights_20_epochs_step_1_epochs_valid.hdf5')\n",
    "# best_RNN_textdata_weights_10_epochs_step_1_epochs_valid\n",
    "# best_RNN_textdata_weights_20_epochs_step_1_epochs_valid\n",
    "# best_RNN_textdata_weights_28_epochs_step_1_epochs_valid_2layers\n",
    "\n",
    "model_deep_rnn = get_deeper_rnn()\n",
    "model_deep_rnn.load_weights('best_RNN_dropout_50_epochs.hdf5')\n",
    "\n",
    "model = model_deep_rnn\n",
    "N = 2\n",
    "initial_place = 0\n",
    "test_size = 100\n",
    "X_text_str = text_validation[initial_place:initial_place+test_size] #Arranco del principio\n",
    "#X_text_str = text_validation[11352:11452] #Arrancho de un lugar que tenga mayusculas\n",
    "\n",
    "for i in range(N):\n",
    "    X_test = chars_to_one_hot(X_text_str[i:], chars)\n",
    "    probs = model.predict(X_test)\n",
    "    #new_char = indices_to_chars[sample_from_probabilities(probs)]\n",
    "    probs_norm = probs/probs.sum()\n",
    "    print(probs_norm.shape)\n",
    "    print(probs_norm[0].sum())\n",
    "    print(np.argmax(probs[0]), sample_from_probabilities(probs,1), sample(probs_norm[0],0.1))\n",
    "    new_char = indices_to_chars[sample(probs_norm[0],0.01)]\n",
    "    X_text_str = X_text_str + new_char\n",
    "print(X_text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.42021868,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.28162739,  0.        ,\n",
       "        0.        ,  0.29815391,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what/sum(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/egpu/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(what/sum(what),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AXOLOTL\n",
    "HUBO un tiempo en que yo pensaba mucho en los axolotl.\n",
    "Iba a verlos al acuario del Jardín de alto de los pasajeros. Es esa menos se acosta\n",
    "de su mujer. El conejo entraron a los caracoles, y la mujer\n",
    "desde los comentamientos de su carrera de los deseos\n",
    "de la mano y encontró con el concierto.\n",
    "\n",
    "**Resultados**:\n",
    "- Aprendio enters\n",
    "- Despues de un punto viene una mayuscula\n",
    "- Plural: los caracoles, los deseos, los comentarmientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sample_from_probabilities(probabilities, topn=None):\n",
    "    print(len(probabilities))\n",
    "    topn = len(probabilities)\n",
    "    \"\"\"Roll the dice to produce a random integer in the [0..ALPHASIZE] range,\n",
    "    according to the provided probabilities. If topn is specified, only the\n",
    "    topn highest probabilities are taken into account.\n",
    "    :param probabilities: a list of size ALPHASIZE with individual probabilities\n",
    "    :param topn: the number of highest probabilities to consider. Defaults to all of them.\n",
    "    :return: a random integer\n",
    "    \"\"\"\n",
    "    p = np.squeeze(probabilities)\n",
    "    p[np.argsort(p)[:-topn]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    return np.random.choice(topn, 1, p=p)[0]\n",
    "\n",
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = np.log(a) / temperature\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [0.15, 0.34, 0.36, 0.15, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 327 µs, sys: 122 µs, total: 449 µs\n",
      "Wall time: 347 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/egpu/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sample(a, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 510 µs, sys: 353 µs, total: 863 µs\n",
      "Wall time: 720 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time sample_from_probabilities(a, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = encode_io_pairs(text_train, chars, 1,1)\n",
    "X_validation, y_validation = encode_io_pairs(text_validation, chars, 1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383052, 1, 88)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  (1, 88)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 1, 200)            231200    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 88)                17688     \n",
      "=================================================================\n",
      "Total params: 569,688\n",
      "Trainable params: 569,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(1, 1)\n",
    "model_full_batch = get_deeper_rnn()\n",
    "model_full_batch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  (1, 88)\n",
      "Train on 383052 samples, validate on 351033 samples\n",
      "Epoch 1/40\n",
      "383000/383052 [============================>.] - ETA: 0s - loss: 2.5878Epoch 00000: val_loss improved from inf to 2.46046, saving model to one_char.hdf5\n",
      "383052/383052 [==============================] - 171s - loss: 2.5878 - val_loss: 2.4605\n",
      "Epoch 2/40\n",
      "383000/383052 [============================>.] - ETA: 0s - loss: 2.4466Epoch 00001: val_loss improved from 2.46046 to 2.44593, saving model to one_char.hdf5\n",
      "383052/383052 [==============================] - 172s - loss: 2.4466 - val_loss: 2.4459\n",
      "Epoch 3/40\n",
      "383000/383052 [============================>.] - ETA: 0s - loss: 2.4258Epoch 00002: val_loss improved from 2.44593 to 2.43870, saving model to one_char.hdf5\n",
      "383052/383052 [==============================] - 186s - loss: 2.4259 - val_loss: 2.4387\n",
      "Epoch 4/40\n",
      "156600/383052 [===========>..................] - ETA: 95s - loss: 2.4181"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-acff44b14af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "model = get_deeper_rnn()\n",
    "checkpointer = ModelCheckpoint(filepath='one_char.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n",
    "                    validation_data = (X_validation, y_validation),\n",
    "                    callbacks=[checkpointer, plo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  (1, 88)\n",
      "Train on 383052 samples, validate on 351033 samples\n",
      "Epoch 1/40\n",
      "383000/383052 [============================>.] - ETA: 0s - loss: 2.5720Epoch 00000: val_loss improved from inf to 2.48893, saving model to one_char.hdf5\n",
      "383052/383052 [==============================] - 186s - loss: 2.5719 - val_loss: 2.4889\n",
      "Epoch 2/40\n",
      " 94600/383052 [======>.......................] - ETA: 114s - loss: 2.5042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c6cec2385045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     callbacks=[checkpointer], shuffle=False)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mllab/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "model = get_deeper_rnn()\n",
    "checkpointer = ModelCheckpoint(filepath='one_char.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=40, verbose = 1, \n",
    "                    validation_data = (X_validation, y_validation),\n",
    "                    callbacks=[checkpointer], shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
